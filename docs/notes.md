


1.Markdown / parse_mode (Telegram)

Проверено:
- parse_mode (Markdown/HTML) в боте сейчас НЕ включён (ни глобально, ни локально).
- В живых тестах Telegram (`care / vaccines / emergency`, сравнения, списки) символы `**` не появляются.
- При этом иногда заголовки выглядят визуально выделенными (вероятно, за счёт формулировок, а не Markdown) — и это воспринимается нормально / даже хорошо.

Вывод:
- Включение `parse_mode=Markdown` возможно (1 строка в `main.py`), если в будущем начнут появляться `**` или нужна более стабильная разметка.
- На текущем этапе решено НЕ внедрять parse_mode, т.к. реальной проблемы в UX нет.

Заметка на будущее:
- Если пользователи начнут видеть `**Заголовок**` со звёздочками — первым делом включить глобальный parse_mode.



2.в промпте спрашивать про фото
3.скорая на срочная помощь
4.может в про режиме сделать если при нажатии собака/кошка/другое - допустим скорая помощь - и опишите питомца. Если в этом режиме юзер описывает питомца, то session открывается новый и на полчаса как на free только тут без лимита и с фото. или вообще сделать кнопки типа сбросить память и отвечать только по анкете











# LLM_KNOWN_ISSUES_UPDATED.md

Рабочий лог возможных улучшений промптов.  
Фиксируем **только наблюдения**, которые *могут* потребовать правок промптов.  
Решение о правках принимается **только после живых диалогов**.

## Легенда
- **P0** — потенциальный риск безопасности / критичный UX  
- **P1** — заметная UX-шероховатость  
- **P2** — вкусовщина / стилистика / допускается как есть  


---


## P0 — возможные правки промптов (если подтвердится в живых диалогах)

### Self-harm / суицидальные мысли (нерелевантный, но чувствительный запрос)
**Наблюдение:**  
При запросах о самоповреждении модель даёт поддерживающий, корректный с точки зрения безопасности ответ, но это формально конфликтует с общим правилом “нерелевантное → редирект к питомцам”.

**Риск:**  
Без явного исключения поведение выглядит “случайным”, а не осознанным.

**Возможная правка (если потребуется):**
- Зафиксировать исключение:  
  при self-harm → поддерживающий безопасный ответ + рекомендация обратиться за помощью, **без немедленного редиректа к питомцам**.

---

### Опасные / незаконные инструкции (взлом, оружие, взрывчатка, наркотики)
**Наблюдение:**  
Сейчас модель чаще делает мягкий редирект к теме питомцев без явного отказа. Фактической утечки или помощи нет.

**Риск:**  
При смене модели или параметров возможна деградация поведения.

**Возможная правка (если потребуется):**
- Добавить короткую явную границу:  
  “С этим я не могу помочь” → затем редирект к питомцам.  
  Без морализации и объяснений.


---


## P1 — возможные UX-шероховатости

### Галлюцинация “на фото”, когда фото не прикреплено
**Наблюдение:**  
В отдельных ответах модель начинает с формулировок вида “Птица на фото…”, хотя изображения в текущем сообщении нет.

**Риск:**  
Создаётся ощущение, что модель “видит” то, чего нет.

**Возможная правка (если потребуется):**
- Усилить правило:  
  если `image_url` нет → не утверждать, что фото видно сейчас;  
  допустимы только условные ссылки на прошлый контекст  
  (“если я правильно понял по прошлому фото…”) + просьба прислать фото ещё раз.

---

### Ответы с рецептами / инструкциями на полностью нерелевантные темы
**Наблюдение:**  
Иногда модель отвечает по существу на нерелевантный запрос (например, рецепт еды), вместо редиректа к питомцам.

**Риск:**  
Размывается продуктовая роль “помощник владельцам питомцев”.

**Возможная правка (если потребуется):**
- Уточнить правило нерелевантности:  
  не давать инструкции / рецепты / советы по теме запроса,  
  даже если запрос “безопасный”.

---

### Чрезмерно структурированные ответы (Markdown, нумерация)
**Наблюдение:**  
Иногда ответы выглядят более “лекционными”, чем разговорными (жирные заголовки, списки).

**Риск:**  
Может восприниматься как менее “живой” стиль.

**Возможная правка (если потребуется):**
- Смягчить указания по структуре или явно ограничить использование Markdown.

### Vision: ответы при неинформативных изображениях (плохое фото, пустой кадр)
**Наблюдение:**  
При вопросах вида «кто на фото» и неинформативном изображении
(размыто / темно / нет деталей) модель ранее использовала формулировки,
похожие на identity-отказ («не могу сказать, кто изображён»).

**Текущий статус:**  
Исправлено на уровне `VISION_RULES`:
- вместо identity-формулировок используется
  «на фото не удаётся рассмотреть объект/детали»;
- поведение считается корректным и не требует дальнейших правок,
если не появятся новые регрессии.

**Наблюдать:**  
- не возвращается ли модель к формулировкам про «кто изображён»;
- не появляются ли галлюцинации объекта при полностью пустых кадрах.

### Vision: влияние истории диалога на ответы по фото
**Наблюдение:**  
Если в истории диалога присутствовал vision-отказ,
модель могла повторять отказ в следующих ответах,
даже при корректных изображениях.

**Текущий статус:**  
Исправлено архитектурно:
- vision-отказы сохраняются в session как `[vision_refusal_ignored]`;
- такие turns исключаются из context prefix перед вызовом LLM.

**Риск:**  
Минимальный. Механизм изоляции отказов признан устойчивым.

### Vision: интерпретация нерелевантных изображений
**Наблюдение:**  
При нерелевантных фото (не человек) модель иногда даёт интерпретацию изображения,
вместо мягкого возврата к теме питомцев.

**Статус:**  
Осознанно оставлено как есть.  
Ужесточение фильтра может привести к ложным отказам на валидные сценарии
(корм, предметы ухода, фрагменты тела питомца).

**Действие:**  
Наблюдать в живых диалогах. Правки — только при подтверждённом UX-негативе.

### Различия в стиле ответов при смене LLM-провайдера (Text)

**Наблюдение:**  
При использовании разных текстовых провайдеров (OpenAI vs OpenRouter)
возможны небольшие различия в стиле и структуре ответов
(длина абзацев, степень формализации).

**Статус:**  
Ожидаемое поведение.  
Осознанно допускается в рамках Free / Pro и текущей архитектуры.

**Действие:**  
Наблюдать в живых диалогах.  
Правки промптов — только при подтверждённом UX-негативе.

### Частота и формулировка запроса фото в текстовых ответах (Free)

**Наблюдение:**  
В режимах `care / vaccines / emergency` модель теперь может
мягко предлагать прислать фото при вопросах о внешних признаках
(кожа, уши, глаза и т.п.).  
Поведение не повторяется в рамках одной session.

**Потенциальный риск:**  
- в отдельных кейсах просьба о фото может звучать слишком осторожно;
- частота срабатывания зависит от формулировки вопроса и модели.

**Текущий статус:**  
Осознанно принято как есть для MVP.  
Дальнейшая калибровка — только по результатам живых диалогов.


---


## P2 — стилистика / допускается как есть

### Дополнительные “расширяющие” блоки в конце ответа
**Наблюдение:**  
Иногда в узких вопросах модель добавляет профилактику, питание, паразитов “заодно”.

**Комментарий:**  
Полезно, но не всегда уместно.  
Пока не править — смотреть, раздражает ли в реальных диалогах.

---

### Формулировки типа «у вашего ветеринара или в клинике»
**Наблюдение:**  
Иногда звучит как разделение одного и того же.

**Комментарий:**  
Чисто стилистическая правка, не критично.

---

## Принцип работы с этим файлом
- **Ничего не правим автоматически.**
- Любая запись → сначала проверяется в живых диалогах (Telegram).
- В промпты идут **только P0 / подтверждённые P1**.
- P2 — копим и смотрим динамику.

### Vision: краткость ответов при прикладных вопросах с фото
**Наблюдение:**  
При вопросах про уход / корм / симптомы и наличии фото
ответы могут выглядеть короче, чем при обзорных вопросах по фото.

**Комментарий:**  
Это осознанное поведение:
- используется 1 короткое наблюдение по фото как “якорь”;
- основной фокус — на рекомендации по сути вопроса.

**Статус:**  
Допускается как есть, наблюдать реакцию пользователей.

